{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d764d98",
   "metadata": {},
   "source": [
    "# LSTM Model with TF-IDF Embeddings\n",
    "## Drug Reviews Classification - Gershom\n",
    "\n",
    "**Model**: LSTM (Long Short-Term Memory) / BiLSTM\n",
    "**Embedding**: TF-IDF (5000 features, balanced config)\n",
    "**Task**: Drug review rating prediction\n",
    "\n",
    "---\n",
    "\n",
    "### Important Note:\n",
    "TF-IDF produces sparse vectors (not dense word embeddings), so we use a different architecture:\n",
    "- NO embedding layer needed\n",
    "- TF-IDF vectors fed directly to Dense layers OR reshaped for LSTM\n",
    "- This notebook shows LSTM architecture adapted for TF-IDF features\n",
    "\n",
    "### Notebook Structure:\n",
    "1. Setup and Data Loading\n",
    "2. TF-IDF Vectorization\n",
    "3. LSTM Model Architecture (TF-IDF adapted)\n",
    "4. Training & Evaluation\n",
    "5. Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cce513",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ef93e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      3\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Bidirectional, Dense, Dropout, Reshape, Input\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Shared modules\n",
    "from src.data_utils import DataLoader, create_dataset_from_dataframe\n",
    "from src.preprocessing import get_preprocessor, TextPreprocessor\n",
    "from src.eda import EDAAnalyzer\n",
    "from embeddings.tfidf_embedding import TfidfEmbedding, get_tfidf_embedding\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05bf6d6",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ecc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "TRAIN_PATH = '../data/drug_review_train.csv'\n",
    "VAL_PATH = '../data/drug_review_validation.csv'\n",
    "TEST_PATH = '../data/drug_review_test.csv'\n",
    "\n",
    "# Data columns\n",
    "TEXT_COLUMN = 'review'\n",
    "LABEL_COLUMN = 'rating'\n",
    "\n",
    "# Preprocessing - TF-IDF works better with minimal preprocessing\n",
    "PREPROCESSING_CONFIG = 'moderate'  # minimal, moderate, or aggressive\n",
    "\n",
    "# Embedding configuration\n",
    "EMBEDDING_TYPE = 'tfidf'\n",
    "EMBEDDING_CONFIG = 'balanced'  # 5000 features\n",
    "TFIDF_MAX_FEATURES = 5000\n",
    "\n",
    "# Model architecture - Different for TF-IDF\n",
    "USE_LSTM = True  # Set False to use Dense-only architecture (faster)\n",
    "USE_BIDIRECTIONAL = True  # Set to True for BiLSTM, False for LSTM\n",
    "LSTM_UNITS = 64  # Smaller since TF-IDF already has 5000 features\n",
    "DROPOUT_RATE = 0.4  # Higher dropout for TF-IDF\n",
    "RECURRENT_DROPOUT = 0.2\n",
    "DENSE_UNITS = 128\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20  # TF-IDF models may need more epochs\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 3\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"Model type: {'LSTM' if USE_LSTM else 'Dense-only'}\")\n",
    "if USE_LSTM:\n",
    "    print(f\"LSTM variant: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"Embedding: {EMBEDDING_TYPE} ({EMBEDDING_CONFIG})\")\n",
    "print(f\"TF-IDF features: {TFIDF_MAX_FEATURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6901027",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55143c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df = pd.read_csv(VAL_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(val_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")\n",
    "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
    "print(f\"\\nClass distribution (train):\")\n",
    "print(train_df[LABEL_COLUMN].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = get_preprocessor(PREPROCESSING_CONFIG)\n",
    "print(f\"Using '{PREPROCESSING_CONFIG}' preprocessing configuration\")\n",
    "\n",
    "# TF-IDF uses RAW TEXT (joined back from tokens), not token lists\n",
    "print(\"\\nPreprocessing texts...\")\n",
    "train_texts = train_df[TEXT_COLUMN].fillna('').tolist()\n",
    "val_texts = val_df[TEXT_COLUMN].fillna('').tolist()\n",
    "test_texts = test_df[TEXT_COLUMN].fillna('').tolist()\n",
    "\n",
    "# Process texts (returns strings, not tokens)\n",
    "train_processed = preprocessor.process_batch(train_texts)\n",
    "val_processed = preprocessor.process_batch(val_texts)\n",
    "test_processed = preprocessor.process_batch(test_texts)\n",
    "\n",
    "# Extract labels\n",
    "train_labels = train_df[LABEL_COLUMN].values\n",
    "val_labels = val_df[LABEL_COLUMN].values\n",
    "test_labels = test_df[LABEL_COLUMN].values\n",
    "\n",
    "print(f\"✓ Preprocessing complete!\")\n",
    "print(f\"Example processed review: {train_processed[0][:100]}...\")  # First 100 chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90644630",
   "metadata": {},
   "source": [
    "## 4. Create TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba329d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit TF-IDF\n",
    "print(\"Training TF-IDF vectorizer...\")\n",
    "tfidf_model = get_tfidf_embedding(EMBEDDING_CONFIG)\n",
    "\n",
    "# Fit on training data\n",
    "tfidf_model.fit(train_processed)\n",
    "\n",
    "# Transform all datasets to dense arrays\n",
    "X_train = tfidf_model.transform_dense(train_processed)\n",
    "X_val = tfidf_model.transform_dense(val_processed)\n",
    "X_test = tfidf_model.transform_dense(test_processed)\n",
    "\n",
    "print(\"\\n✓ TF-IDF vectorization complete!\")\n",
    "print(f\"Feature dimension: {tfidf_model.get_embedding_dim()}\")\n",
    "print(f\"Vocabulary size: {len(tfidf_model.get_vocabulary())}\")\n",
    "print(f\"\\nTrain shape: {X_train.shape}\")\n",
    "print(f\"Val shape: {X_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d51c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sparsity\n",
    "sparsity_train = (X_train == 0).sum() / X_train.size * 100\n",
    "print(f\"\\nTF-IDF sparsity: {sparsity_train:.2f}% of values are zero\")\n",
    "print(f\"Average non-zero features per document: {(X_train != 0).sum(axis=1).mean():.1f}\")\n",
    "\n",
    "# Show top TF-IDF terms\n",
    "print(\"\\nTop 20 TF-IDF features:\")\n",
    "print(tfidf_model.get_top_terms(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b049ad",
   "metadata": {},
   "source": [
    "## 5. Process Labels for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108757d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the rating distribution\n",
    "print(\"Rating distribution:\")\n",
    "print(train_df[LABEL_COLUMN].value_counts().sort_index())\n",
    "\n",
    "# Binary classification: ratings >= 6 = positive (1), < 6 = negative (0)\n",
    "CLASSIFICATION_TYPE = 'binary'  # 'binary', 'multiclass', or 'regression'\n",
    "THRESHOLD = 6  # For binary classification\n",
    "\n",
    "if CLASSIFICATION_TYPE == 'binary':\n",
    "    train_y = (train_labels >= THRESHOLD).astype(int)\n",
    "    val_y = (val_labels >= THRESHOLD).astype(int)\n",
    "    test_y = (test_labels >= THRESHOLD).astype(int)\n",
    "    NUM_CLASSES = 2\n",
    "    print(f\"\\nBinary classification: >= {THRESHOLD} = positive\")\n",
    "    print(f\"Train class distribution: {np.bincount(train_y)}\")\n",
    "elif CLASSIFICATION_TYPE == 'multiclass':\n",
    "    train_y = train_labels.astype(int) - 1\n",
    "    val_y = val_labels.astype(int) - 1\n",
    "    test_y = test_labels.astype(int) - 1\n",
    "    NUM_CLASSES = len(np.unique(train_y))\n",
    "    print(f\"\\nMulti-class classification: {NUM_CLASSES} classes\")\n",
    "else:  # regression\n",
    "    train_y = train_labels.astype(float)\n",
    "    val_y = val_labels.astype(float)\n",
    "    test_y = test_labels.astype(float)\n",
    "    NUM_CLASSES = 1\n",
    "    print(\"\\nRegression: Predicting exact rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb34f64d",
   "metadata": {},
   "source": [
    "## 6. Prepare Data for LSTM (Reshape TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3de904",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_LSTM:\n",
    "    # LSTM expects 3D input: (batch, timesteps, features)\n",
    "    # We'll reshape TF-IDF vectors: treat each feature as a timestep with 1 value\n",
    "    # OR: split features into chunks\n",
    "    \n",
    "    # Option 1: Each TF-IDF feature as a timestep (simple but may not be ideal)\n",
    "    CHUNK_SIZE = 100  # Split 5000 features into chunks of 100\n",
    "    TIMESTEPS = TFIDF_MAX_FEATURES // CHUNK_SIZE\n",
    "    \n",
    "    print(f\"\\nReshaping TF-IDF for LSTM...\")\n",
    "    print(f\"Original shape: {X_train.shape}\")\n",
    "    \n",
    "    # Pad to make divisible by chunk size\n",
    "    target_size = TIMESTEPS * CHUNK_SIZE\n",
    "    if X_train.shape[1] < target_size:\n",
    "        X_train = np.pad(X_train, ((0, 0), (0, target_size - X_train.shape[1])), mode='constant')\n",
    "        X_val = np.pad(X_val, ((0, 0), (0, target_size - X_val.shape[1])), mode='constant')\n",
    "        X_test = np.pad(X_test, ((0, 0), (0, target_size - X_test.shape[1])), mode='constant')\n",
    "    \n",
    "    # Reshape to (samples, timesteps, features_per_timestep)\n",
    "    X_train_reshaped = X_train[:, :target_size].reshape(-1, TIMESTEPS, CHUNK_SIZE)\n",
    "    X_val_reshaped = X_val[:, :target_size].reshape(-1, TIMESTEPS, CHUNK_SIZE)\n",
    "    X_test_reshaped = X_test[:, :target_size].reshape(-1, TIMESTEPS, CHUNK_SIZE)\n",
    "    \n",
    "    print(f\"Reshaped for LSTM: {X_train_reshaped.shape}\")\n",
    "    print(f\"(samples, timesteps={TIMESTEPS}, features_per_step={CHUNK_SIZE})\")\n",
    "    \n",
    "    # Use reshaped data\n",
    "    X_train_input = X_train_reshaped\n",
    "    X_val_input = X_val_reshaped\n",
    "    X_test_input = X_test_reshaped\n",
    "else:\n",
    "    # For Dense-only model, use original 2D shape\n",
    "    X_train_input = X_train\n",
    "    X_val_input = X_val\n",
    "    X_test_input = X_test\n",
    "    print(\"\\nUsing 2D TF-IDF vectors for Dense-only model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f555377",
   "metadata": {},
   "source": [
    "## 7. Build Model (LSTM or Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tfidf_lstm_model(\n",
    "    input_shape,\n",
    "    lstm_units=64,\n",
    "    dropout_rate=0.4,\n",
    "    recurrent_dropout=0.2,\n",
    "    dense_units=128,\n",
    "    num_classes=2,\n",
    "    use_bidirectional=True,\n",
    "    classification_type='binary'\n",
    "):\n",
    "    \"\"\"Build LSTM model for TF-IDF features.\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layers (input is already 3D from reshape)\n",
    "    if use_bidirectional:\n",
    "        model.add(Bidirectional(\n",
    "            LSTM(\n",
    "                lstm_units,\n",
    "                dropout=dropout_rate,\n",
    "                recurrent_dropout=recurrent_dropout,\n",
    "                input_shape=input_shape\n",
    "            ),\n",
    "            name='bilstm'\n",
    "        ))\n",
    "    else:\n",
    "        model.add(LSTM(\n",
    "            lstm_units,\n",
    "            dropout=dropout_rate,\n",
    "            recurrent_dropout=recurrent_dropout,\n",
    "            input_shape=input_shape,\n",
    "            name='lstm'\n",
    "        ))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Dense(dense_units, activation='relu', name='dense_1'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(dense_units // 2, activation='relu', name='dense_2'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer\n",
    "    if classification_type == 'binary':\n",
    "        model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "        loss = 'binary_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "    elif classification_type == 'multiclass':\n",
    "        model.add(Dense(num_classes, activation='softmax', name='output'))\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "    else:  # regression\n",
    "        model.add(Dense(1, activation='linear', name='output'))\n",
    "        loss = 'mse'\n",
    "        metrics = ['mae']\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=loss,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_tfidf_dense_model(\n",
    "    input_dim,\n",
    "    dense_units=256,\n",
    "    dropout_rate=0.4,\n",
    "    num_classes=2,\n",
    "    classification_type='binary'\n",
    "):\n",
    "    \"\"\"Build Dense-only model for TF-IDF features (faster alternative).\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Dense(dense_units, activation='relu', input_dim=input_dim, name='dense_1'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(dense_units // 2, activation='relu', name='dense_2'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(dense_units // 4, activation='relu', name='dense_3'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer\n",
    "    if classification_type == 'binary':\n",
    "        model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "        loss = 'binary_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "    elif classification_type == 'multiclass':\n",
    "        model.add(Dense(num_classes, activation='softmax', name='output'))\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "    else:  # regression\n",
    "        model.add(Dense(1, activation='linear', name='output'))\n",
    "        loss = 'mse'\n",
    "        metrics = ['mae']\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=loss,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "print(\"Building model...\")\n",
    "if USE_LSTM:\n",
    "    input_shape = (X_train_input.shape[1], X_train_input.shape[2])  # (timesteps, features)\n",
    "    model = build_tfidf_lstm_model(\n",
    "        input_shape=input_shape,\n",
    "        lstm_units=LSTM_UNITS,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        recurrent_dropout=RECURRENT_DROPOUT,\n",
    "        dense_units=DENSE_UNITS,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        use_bidirectional=USE_BIDIRECTIONAL,\n",
    "        classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "else:\n",
    "    input_dim = X_train_input.shape[1]\n",
    "    model = build_tfidf_dense_model(\n",
    "        input_dim=input_dim,\n",
    "        dense_units=DENSE_UNITS * 2,  # Larger for Dense-only\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "print(\"\\n✓ Model built successfully!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60e24c",
   "metadata": {},
   "source": [
    "## 8. Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbe236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='best_lstm_tfidf_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72d363c",
   "metadata": {},
   "source": [
    "## 9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b17281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"\\nStarting training...\")\n",
    "print(f\"Model: {'LSTM with TF-IDF' if USE_LSTM else 'Dense with TF-IDF'}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Max epochs: {EPOCHS}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_input,\n",
    "    train_y,\n",
    "    validation_data=(X_val_input, val_y),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476946e",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c890ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy plot (for classification)\n",
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    axes[1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    axes[1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "else:  # regression\n",
    "    axes[1].plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "    axes[1].plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "    axes[1].set_title('Model MAE', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a83a51",
   "metadata": {},
   "source": [
    "## 11. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e202e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = model.evaluate(X_test_input, test_y, verbose=1)\n",
    "\n",
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    print(f\"\\nTest Loss: {test_results[0]:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nTest Loss (MSE): {test_results[0]:.4f}\")\n",
    "    print(f\"Test MAE: {test_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "test_predictions = model.predict(X_test_input, verbose=1)\n",
    "\n",
    "if CLASSIFICATION_TYPE == 'binary':\n",
    "    test_pred_classes = (test_predictions > 0.5).astype(int).flatten()\n",
    "elif CLASSIFICATION_TYPE == 'multiclass':\n",
    "    test_pred_classes = np.argmax(test_predictions, axis=1)\n",
    "else:  # regression\n",
    "    test_pred_classes = test_predictions.flatten()\n",
    "\n",
    "print(\"✓ Predictions generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de21ad",
   "metadata": {},
   "source": [
    "## 12. Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436374c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    # Classification report\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLASSIFICATION REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(test_y, test_pred_classes, digits=4))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_y, test_pred_classes)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(test_y, test_pred_classes)\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Support': support\n",
    "    })\n",
    "    \n",
    "    print(\"\\nPer-Class Metrics:\")\n",
    "    print(metrics_df.to_string())\n",
    "else:\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    \n",
    "    mse = mean_squared_error(test_y, test_pred_classes)\n",
    "    mae = mean_absolute_error(test_y, test_pred_classes)\n",
    "    r2 = r2_score(test_y, test_pred_classes)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"REGRESSION METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5521b61",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b9491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results dictionary\n",
    "results = {\n",
    "    'model': 'LSTM_TF-IDF' if USE_LSTM else 'Dense_TF-IDF',\n",
    "    'embedding': f'{EMBEDDING_TYPE}_{EMBEDDING_CONFIG}',\n",
    "    'tfidf_features': TFIDF_MAX_FEATURES,\n",
    "    'lstm_units': LSTM_UNITS if USE_LSTM else 'N/A',\n",
    "    'preprocessing': PREPROCESSING_CONFIG,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs_trained': len(history.history['loss']),\n",
    "    'classification_type': CLASSIFICATION_TYPE,\n",
    "}\n",
    "\n",
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    results['test_accuracy'] = float(test_results[1])\n",
    "    results['test_loss'] = float(test_results[0])\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(test_y, test_pred_classes, average='weighted')\n",
    "    results['precision'] = float(precision)\n",
    "    results['recall'] = float(recall)\n",
    "    results['f1_score'] = float(f1)\n",
    "else:\n",
    "    results['test_mse'] = float(test_results[0])\n",
    "    results['test_mae'] = float(test_results[1])\n",
    "    results['r2_score'] = float(r2_score(test_y, test_pred_classes))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Save results to JSON\n",
    "import json\n",
    "with open('lstm_tfidf_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Results saved to 'lstm_tfidf_results.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6e1e1",
   "metadata": {},
   "source": [
    "## 14. Model Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e382b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LSTM + TF-IDF - EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel: {'LSTM with TF-IDF' if USE_LSTM else 'Dense with TF-IDF'}\")\n",
    "print(f\"Embedding: TF-IDF (5000 features)\")\n",
    "print(f\"Total Parameters: {model.count_params():,}\")\n",
    "\n",
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    print(f\"\\nFinal Test Accuracy: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"F1-Score: {results['f1_score']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nFinal Test MAE: {results['test_mae']:.4f}\")\n",
    "    print(f\"R² Score: {results['r2_score']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL THREE EMBEDDINGS COMPLETE!\")\n",
    "print(\"Compare results from:\")\n",
    "print(\"- lstm_word2vec_results.json\")\n",
    "print(\"- lstm_glove_results.json\")\n",
    "print(\"- lstm_tfidf_results.json\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
