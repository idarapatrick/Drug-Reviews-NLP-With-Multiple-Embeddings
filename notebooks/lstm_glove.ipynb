{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03efcfdc",
   "metadata": {},
   "source": [
    "# LSTM Model with GloVe Embeddings\n",
    "## Drug Reviews Classification - Gershom\n",
    "\n",
    "**Model**: LSTM (Long Short-Term Memory) / BiLSTM\n",
    "**Embedding**: GloVe (200-dim, medium config)\n",
    "**Task**: Drug review rating prediction\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook Structure:\n",
    "1. Setup and Data Loading\n",
    "2. GloVe Embedding Training\n",
    "3. LSTM Model Architecture\n",
    "4. Training & Evaluation\n",
    "5. Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0311ae",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd737f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Bidirectional, Dense, Dropout, Embedding, \n",
    "    Input, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Shared modules\n",
    "from src.data_utils import DataLoader, create_dataset_from_dataframe\n",
    "from src.preprocessing import get_preprocessor, TextPreprocessor\n",
    "from src.eda import EDAAnalyzer\n",
    "from embeddings.glove_embedding import GloVeEmbedding, get_glove_embedding\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da5a1a",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d64549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "TRAIN_PATH = '../data/drug_review_train.csv'\n",
    "VAL_PATH = '../data/drug_review_validation.csv'\n",
    "TEST_PATH = '../data/drug_review_test.csv'\n",
    "\n",
    "# Data columns\n",
    "TEXT_COLUMN = 'review'\n",
    "LABEL_COLUMN = 'rating'\n",
    "\n",
    "# Preprocessing\n",
    "PREPROCESSING_CONFIG = 'moderate'  # minimal, moderate, or aggressive\n",
    "\n",
    "# Embedding configuration\n",
    "EMBEDDING_TYPE = 'glove'\n",
    "EMBEDDING_CONFIG = 'medium'  # 200-dim, 15 iterations\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "# Model architecture\n",
    "USE_BIDIRECTIONAL = True  # Set to True for BiLSTM, False for LSTM\n",
    "LSTM_UNITS = 128\n",
    "DROPOUT_RATE = 0.3\n",
    "RECURRENT_DROPOUT = 0.2\n",
    "DENSE_UNITS = 64\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 3\n",
    "\n",
    "# Sequence parameters\n",
    "MAX_SEQUENCE_LENGTH = 200  # Maximum number of words per review\n",
    "VOCAB_SIZE = 10000  # Maximum vocabulary size\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"Model type: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"Embedding: {EMBEDDING_TYPE} ({EMBEDDING_CONFIG})\")\n",
    "print(f\"LSTM units: {LSTM_UNITS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3591908",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df = pd.read_csv(VAL_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(val_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")\n",
    "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
    "print(f\"\\nClass distribution (train):\")\n",
    "print(train_df[LABEL_COLUMN].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = get_preprocessor(PREPROCESSING_CONFIG)\n",
    "print(f\"Using '{PREPROCESSING_CONFIG}' preprocessing configuration\")\n",
    "\n",
    "# Get tokenized texts (GloVe needs tokens, not strings)\n",
    "print(\"\\nPreprocessing and tokenizing...\")\n",
    "train_texts = train_df[TEXT_COLUMN].fillna('').tolist()\n",
    "val_texts = val_df[TEXT_COLUMN].fillna('').tolist()\n",
    "test_texts = test_df[TEXT_COLUMN].fillna('').tolist()\n",
    "\n",
    "# Get tokenized versions for GloVe training\n",
    "train_tokens = preprocessor.get_tokens_batch(train_texts)\n",
    "val_tokens = preprocessor.get_tokens_batch(val_texts)\n",
    "test_tokens = preprocessor.get_tokens_batch(test_texts)\n",
    "\n",
    "# Extract labels\n",
    "train_labels = train_df[LABEL_COLUMN].values\n",
    "val_labels = val_df[LABEL_COLUMN].values\n",
    "test_labels = test_df[LABEL_COLUMN].values\n",
    "\n",
    "print(f\"✓ Tokenization complete!\")\n",
    "print(f\"Example tokenized review: {train_tokens[0][:20]}...\")  # First 20 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab864e7",
   "metadata": {},
   "source": [
    "## 4. Train GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc80bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train GloVe\n",
    "print(\"Training GloVe embeddings...\")\n",
    "glove_model = get_glove_embedding(EMBEDDING_CONFIG)\n",
    "glove_model.fit(train_tokens)\n",
    "\n",
    "print(\"\\n✓ GloVe training complete!\")\n",
    "print(f\"Model info: {glove_model.get_model_info()}\")\n",
    "print(f\"Vocabulary size: {glove_model.get_vocabulary_size()}\")\n",
    "print(f\"Embedding dimension: {glove_model.embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554872a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GloVe embeddings with sample words\n",
    "print(\"\\nTesting GloVe embeddings...\")\n",
    "test_words = ['pain', 'drug', 'effective', 'side', 'effect']\n",
    "\n",
    "for word in test_words:\n",
    "    try:\n",
    "        similar = glove_model.most_similar(word, topn=5)\n",
    "        print(f\"\\n'{word}' most similar:\")\n",
    "        for sim_word, score in similar:\n",
    "            print(f\"  {sim_word}: {score:.3f}\")\n",
    "    except KeyError:\n",
    "        print(f\"\\n'{word}' not in vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328703d9",
   "metadata": {},
   "source": [
    "## 5. Create Sequences and Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from GloVe\n",
    "vocab = glove_model.get_vocab()\n",
    "word_to_idx = {word: idx + 1 for idx, word in enumerate(vocab[:VOCAB_SIZE-1])}  # Reserve 0 for padding\n",
    "word_to_idx['<PAD>'] = 0\n",
    "word_to_idx['<UNK>'] = len(word_to_idx)\n",
    "\n",
    "print(f\"Vocabulary size (with special tokens): {len(word_to_idx)}\")\n",
    "\n",
    "# Convert tokens to sequences\n",
    "def tokens_to_sequences(token_lists, word_to_idx):\n",
    "    sequences = []\n",
    "    for tokens in token_lists:\n",
    "        seq = [word_to_idx.get(token, word_to_idx['<UNK>']) for token in tokens]\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "train_sequences = tokens_to_sequences(train_tokens, word_to_idx)\n",
    "val_sequences = tokens_to_sequences(val_tokens, word_to_idx)\n",
    "test_sequences = tokens_to_sequences(test_tokens, word_to_idx)\n",
    "\n",
    "# Pad sequences\n",
    "train_padded = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "val_padded = pad_sequences(val_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "print(f\"\\nSequence shapes:\")\n",
    "print(f\"Train: {train_padded.shape}\")\n",
    "print(f\"Val: {val_padded.shape}\")\n",
    "print(f\"Test: {test_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding matrix from GloVe\n",
    "print(\"\\nCreating embedding matrix...\")\n",
    "embedding_matrix = np.zeros((len(word_to_idx), EMBEDDING_DIM))\n",
    "\n",
    "for word, idx in word_to_idx.items():\n",
    "    if word not in ['<PAD>', '<UNK>']:\n",
    "        try:\n",
    "            embedding_matrix[idx] = glove_model.get_word_vector(word)\n",
    "        except KeyError:\n",
    "            # Initialize with small random values\n",
    "            embedding_matrix[idx] = np.random.randn(EMBEDDING_DIM) * 0.01\n",
    "\n",
    "print(f\"✓ Embedding matrix shape: {embedding_matrix.shape}\")\n",
    "print(f\"Non-zero rows: {np.count_nonzero(embedding_matrix.any(axis=1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692d5e4",
   "metadata": {},
   "source": [
    "## 6. Process Labels for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the rating distribution to decide on classification strategy\n",
    "print(\"Rating distribution:\")\n",
    "print(train_df[LABEL_COLUMN].value_counts().sort_index())\n",
    "\n",
    "# For this example, let's use binary classification: ratings >= 6 = positive (1), < 6 = negative (0)\n",
    "CLASSIFICATION_TYPE = 'binary'  # 'binary', 'multiclass', or 'regression'\n",
    "THRESHOLD = 6  # For binary classification\n",
    "\n",
    "if CLASSIFICATION_TYPE == 'binary':\n",
    "    train_y = (train_labels >= THRESHOLD).astype(int)\n",
    "    val_y = (val_labels >= THRESHOLD).astype(int)\n",
    "    test_y = (test_labels >= THRESHOLD).astype(int)\n",
    "    NUM_CLASSES = 2\n",
    "    print(f\"\\nBinary classification: >= {THRESHOLD} = positive\")\n",
    "    print(f\"Train class distribution: {np.bincount(train_y)}\")\n",
    "elif CLASSIFICATION_TYPE == 'multiclass':\n",
    "    train_y = train_labels.astype(int) - 1\n",
    "    val_y = val_labels.astype(int) - 1\n",
    "    test_y = test_labels.astype(int) - 1\n",
    "    NUM_CLASSES = len(np.unique(train_y))\n",
    "    print(f\"\\nMulti-class classification: {NUM_CLASSES} classes\")\n",
    "else:  # regression\n",
    "    train_y = train_labels.astype(float)\n",
    "    val_y = val_labels.astype(float)\n",
    "    test_y = test_labels.astype(float)\n",
    "    NUM_CLASSES = 1\n",
    "    print(\"\\nRegression: Predicting exact rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ca952",
   "metadata": {},
   "source": [
    "## 7. Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    embedding_matrix,\n",
    "    max_length,\n",
    "    lstm_units=128,\n",
    "    dropout_rate=0.3,\n",
    "    recurrent_dropout=0.2,\n",
    "    dense_units=64,\n",
    "    num_classes=2,\n",
    "    use_bidirectional=True,\n",
    "    classification_type='binary'\n",
    "):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Embedding layer with pre-trained GloVe weights\n",
    "    model.add(Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_length,\n",
    "        trainable=False,\n",
    "        name='embedding'\n",
    "    ))\n",
    "    \n",
    "    # LSTM layer(s)\n",
    "    if use_bidirectional:\n",
    "        model.add(Bidirectional(\n",
    "            LSTM(\n",
    "                lstm_units,\n",
    "                return_sequences=True,\n",
    "                dropout=dropout_rate,\n",
    "                recurrent_dropout=recurrent_dropout\n",
    "            ),\n",
    "            name='bilstm_1'\n",
    "        ))\n",
    "        model.add(Bidirectional(\n",
    "            LSTM(\n",
    "                lstm_units // 2,\n",
    "                dropout=dropout_rate,\n",
    "                recurrent_dropout=recurrent_dropout\n",
    "            ),\n",
    "            name='bilstm_2'\n",
    "        ))\n",
    "    else:\n",
    "        model.add(LSTM(\n",
    "            lstm_units,\n",
    "            return_sequences=True,\n",
    "            dropout=dropout_rate,\n",
    "            recurrent_dropout=recurrent_dropout,\n",
    "            name='lstm_1'\n",
    "        ))\n",
    "        model.add(LSTM(\n",
    "            lstm_units // 2,\n",
    "            dropout=dropout_rate,\n",
    "            recurrent_dropout=recurrent_dropout,\n",
    "            name='lstm_2'\n",
    "        ))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Dense(dense_units, activation='relu', name='dense_1'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer\n",
    "    if classification_type == 'binary':\n",
    "        model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "        loss = 'binary_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "    elif classification_type == 'multiclass':\n",
    "        model.add(Dense(num_classes, activation='softmax', name='output'))\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "    else:  # regression\n",
    "        model.add(Dense(1, activation='linear', name='output'))\n",
    "        loss = 'mse'\n",
    "        metrics = ['mae']\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=loss,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "print(\"Building LSTM model...\")\n",
    "model = build_lstm_model(\n",
    "    vocab_size=len(word_to_idx),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    max_length=MAX_SEQUENCE_LENGTH,\n",
    "    lstm_units=LSTM_UNITS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    recurrent_dropout=RECURRENT_DROPOUT,\n",
    "    dense_units=DENSE_UNITS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    use_bidirectional=USE_BIDIRECTIONAL,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Model built successfully!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fcde6",
   "metadata": {},
   "source": [
    "## 8. Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef79d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='best_lstm_glove_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"- Early stopping (patience=3)\")\n",
    "print(\"- Learning rate reduction\")\n",
    "print(\"- Model checkpointing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf9be0",
   "metadata": {},
   "source": [
    "## 9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"\\nStarting training...\")\n",
    "print(f\"Model: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Max epochs: {EPOCHS}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "history = model.fit(\n",
    "    train_padded,\n",
    "    train_y,\n",
    "    validation_data=(val_padded, val_y),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f85569",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy plot (for classification)\n",
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    axes[1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    axes[1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "else:  # regression\n",
    "    axes[1].plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "    axes[1].plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "    axes[1].set_title('Model MAE', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f410bd3",
   "metadata": {},
   "source": [
    "## 11. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354732bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = model.evaluate(test_padded, test_y, verbose=1)\n",
    "\n",
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    print(f\"\\nTest Loss: {test_results[0]:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nTest Loss (MSE): {test_results[0]:.4f}\")\n",
    "    print(f\"Test MAE: {test_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "test_predictions = model.predict(test_padded, verbose=1)\n",
    "\n",
    "if CLASSIFICATION_TYPE == 'binary':\n",
    "    test_pred_classes = (test_predictions > 0.5).astype(int).flatten()\n",
    "elif CLASSIFICATION_TYPE == 'multiclass':\n",
    "    test_pred_classes = np.argmax(test_predictions, axis=1)\n",
    "else:  # regression\n",
    "    test_pred_classes = test_predictions.flatten()\n",
    "\n",
    "print(\"✓ Predictions generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6829c",
   "metadata": {},
   "source": [
    "## 12. Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    # Classification report\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLASSIFICATION REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(test_y, test_pred_classes, digits=4))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_y, test_pred_classes)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(test_y, test_pred_classes)\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Support': support\n",
    "    })\n",
    "    \n",
    "    print(\"\\nPer-Class Metrics:\")\n",
    "    print(metrics_df.to_string())\n",
    "else:\n",
    "    # Regression metrics\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    \n",
    "    mse = mean_squared_error(test_y, test_pred_classes)\n",
    "    mae = mean_absolute_error(test_y, test_pred_classes)\n",
    "    r2 = r2_score(test_y, test_pred_classes)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"REGRESSION METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(test_y, test_pred_classes, alpha=0.5)\n",
    "    plt.plot([test_y.min(), test_y.max()], [test_y.min(), test_y.max()], 'r--', lw=2)\n",
    "    plt.xlabel('True Rating')\n",
    "    plt.ylabel('Predicted Rating')\n",
    "    plt.title('Predicted vs True Ratings')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0dd1b",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad378801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results dictionary\n",
    "results = {\n",
    "    'model': 'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM',\n",
    "    'embedding': f'{EMBEDDING_TYPE}_{EMBEDDING_CONFIG}',\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'lstm_units': LSTM_UNITS,\n",
    "    'max_sequence_length': MAX_SEQUENCE_LENGTH,\n",
    "    'vocab_size': len(word_to_idx),\n",
    "    'preprocessing': PREPROCESSING_CONFIG,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs_trained': len(history.history['loss']),\n",
    "    'classification_type': CLASSIFICATION_TYPE,\n",
    "}\n",
    "\n",
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    results['test_accuracy'] = float(test_results[1])\n",
    "    results['test_loss'] = float(test_results[0])\n",
    "    \n",
    "    # Add precision, recall, f1\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(test_y, test_pred_classes, average='weighted')\n",
    "    results['precision'] = float(precision)\n",
    "    results['recall'] = float(recall)\n",
    "    results['f1_score'] = float(f1)\n",
    "else:\n",
    "    results['test_mse'] = float(test_results[0])\n",
    "    results['test_mae'] = float(test_results[1])\n",
    "    results['r2_score'] = float(r2_score(test_y, test_pred_classes))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Save results to JSON\n",
    "import json\n",
    "with open('lstm_glove_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Results saved to 'lstm_glove_results.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b7b60",
   "metadata": {},
   "source": [
    "## 14. Model Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LSTM + GLOVE - EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel: {'BiLSTM' if USE_BIDIRECTIONAL else 'LSTM'}\")\n",
    "print(f\"Embedding: GloVe (200-dim)\")\n",
    "print(f\"Total Parameters: {model.count_params():,}\")\n",
    "\n",
    "if CLASSIFICATION_TYPE in ['binary', 'multiclass']:\n",
    "    print(f\"\\nFinal Test Accuracy: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"F1-Score: {results['f1_score']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nFinal Test MAE: {results['test_mae']:.4f}\")\n",
    "    print(f\"R² Score: {results['r2_score']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEXT: Create lstm_tfidf.ipynb for TF-IDF embeddings\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
